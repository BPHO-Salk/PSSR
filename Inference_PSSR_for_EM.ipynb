{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using PSSR EM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn\n",
    "import PIL\n",
    "import imageio\n",
    "import libtiff\n",
    "import skimage\n",
    "import skimage.filters\n",
    "from utils.utils import FeatureLoss\n",
    "from scipy.ndimage.interpolation import zoom as npzoom\n",
    "from skimage.util import img_as_float32, img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tif_predict_movie_blend_slices(learn, tif_in, orig_out='orig.tif', pred_out='pred.tif', size=128):\n",
    "        data = libtiff.TiffFile(tif_in)\n",
    "        data = data.get_tiff_array()\n",
    "        depths = data.shape[0]\n",
    "        img_max = None        \n",
    "        for depth in progress_bar(list(range(depths))):\n",
    "            img = data[depth].astype(np.float32)\n",
    "            if img_max is None: img_max = img.max() * 1.0\n",
    "            img /= img_max\n",
    "            img = img[np.newaxis, :]\n",
    "            out_img = unet_image_from_tiles_blend(learn, img, tile_sz=size)\n",
    "            pred = (out_img[None]*65535).astype(np.uint16)\n",
    "            pred_img_out = pred_out+f'_slice{depth}.tif'\n",
    "            skimage.io.imsave(pred_img_out,pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take float in with info about mi,ma,max in and spits out (0-1.0)\n",
    "def unet_image_from_tiles_blend(learn, in_img, tile_sz=256, scale=4, overlap_pct=5.0, img_info=None):\n",
    "    n_frames = in_img.shape[0]    \n",
    "\n",
    "    if img_info:\n",
    "        mi, ma, imax = [img_info[fld] for fld in ['mi','ma','img_max']]\n",
    "        in_img = ((in_img - mi) / (ma - mi + 1e-20)).clip(0.,1.)\n",
    "    else:\n",
    "        mi, ma = 0., 1.\n",
    "\n",
    "    in_img  = np.stack([npzoom(in_img[i], scale, order=1) for i in range(n_frames)])\n",
    "    overlap = int(tile_sz*(overlap_pct/100.) // 2 * 2)\n",
    "    step_sz = tile_sz - overlap\n",
    "    h,w = in_img.shape[1:3]\n",
    "    assembled = np.zeros((h,w))\n",
    "\n",
    "    x_seams = set()\n",
    "    y_seams = set()\n",
    "\n",
    "    for x_tile in range(0,math.ceil(w/step_sz)):\n",
    "        for y_tile in range(0,math.ceil(h/step_sz)):\n",
    "            x_start = x_tile*step_sz\n",
    "            x_end = min(x_start + tile_sz, w)\n",
    "            y_start = y_tile*step_sz\n",
    "            y_end = min(y_start + tile_sz, h)\n",
    "            src_tile = in_img[:,y_start:y_end,x_start:x_end]\n",
    "\n",
    "\n",
    "            in_tile = torch.zeros((tile_sz, tile_sz, n_frames))\n",
    "            in_x_size = x_end - x_start\n",
    "            in_y_size = y_end - y_start\n",
    "            if (in_y_size, in_x_size) != src_tile.shape[1:3]: set_trace()\n",
    "            in_tile[0:in_y_size, 0:in_x_size, :] = tensor(src_tile).permute(1,2,0)\n",
    "\n",
    "            if n_frames > 1:\n",
    "                img_in = MultiImage([Image(in_tile[:,:,i][None]) for i in range(n_frames)])\n",
    "            else:\n",
    "                img_in = Image(in_tile[:,:,0][None])\n",
    "            pred, _, _ = learn.predict(img_in)\n",
    "                        \n",
    "            out_tile = pred.data.numpy()[0]\n",
    "            \n",
    "            half_overlap = overlap // 2\n",
    "            left_adj = half_overlap if x_start != 0 else 0\n",
    "            right_adj = half_overlap if x_end != w else 0\n",
    "            top_adj = half_overlap if y_start != 0 else 0\n",
    "            bot_adj = half_overlap if y_end != h else 0\n",
    "\n",
    "            trim_y_start = y_start + top_adj\n",
    "            trim_x_start = x_start + left_adj\n",
    "            trim_y_end = y_end - bot_adj\n",
    "            trim_x_end = x_end - right_adj\n",
    "\n",
    "            out_x_start = left_adj\n",
    "            out_y_start = top_adj\n",
    "            out_x_end = in_x_size - right_adj\n",
    "            out_y_end = in_y_size - bot_adj\n",
    "\n",
    "            assembled[trim_y_start:trim_y_end, trim_x_start:trim_x_end] = out_tile[out_y_start:out_y_end, out_x_start:out_x_end]\n",
    "\n",
    "            if trim_x_start != 0: x_seams.add(trim_x_start)\n",
    "            if trim_y_start != 0: y_seams.add(trim_y_start)\n",
    "\n",
    "    blur_rects = []\n",
    "    blur_size = 5\n",
    "    for x_seam in x_seams:\n",
    "        left = x_seam - blur_size\n",
    "        right = x_seam + blur_size\n",
    "        top, bottom = 0, h\n",
    "        blur_rects.append((slice(top, bottom), slice(left, right)))\n",
    "\n",
    "    for y_seam in y_seams:\n",
    "        top = y_seam - blur_size\n",
    "        bottom = y_seam + blur_size\n",
    "        left, right = 0, w\n",
    "        blur_rects.append((slice(top, bottom), slice(left, right)))\n",
    "\n",
    "    for xs,ys in blur_rects:\n",
    "        assembled[xs,ys] = skimage.filters.gaussian(assembled[xs,ys], sigma=1.0)\n",
    "        \n",
    "    if assembled.min() < 0: assembled -= assembled.min() \n",
    "\n",
    "    return assembled.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set path for test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify accordingly\n",
    "testset_path = Path('stats') \n",
    "testset_name = 'real-world_SEM'\n",
    "\n",
    "lr_path = testset_path/f'LR/{testset_name}'\n",
    "results = testset_path/f'LR-PSSR/{testset_name}'\n",
    "test_files = list(lr_path.glob('*.tif'))\n",
    "\n",
    "if results.exists(): shutil.rmtree(results)\n",
    "results.mkdir(parents=True, mode=0o775, exist_ok=True)\n",
    "\n",
    "print('Processing '+str(len(test_files))+' files...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PSSR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'PSSR_for_EM_1024'\n",
    "learn = load_learner('models/pkl_files', f'{model_name}.pkl')\n",
    "size = int(model_name.split('_')[-1])\n",
    "print(f'{model_name} model is being used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fn in test_files:\n",
    "    print(f'Processing:{fn.stem}')\n",
    "    pred_name = str(results/f'{fn.stem}_pred')\n",
    "    orig_name = results/f'{fn.stem}_orig.tif'\n",
    "    tif_predict_movie_blend_slices(learn, fn, size=size, orig_out=orig_name, pred_out=pred_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
