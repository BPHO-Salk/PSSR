{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSSR 02 - Generate training datasets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9zNGvape2-I",
        "colab_type": "text"
      },
      "source": [
        "# **Point Scanning Super Resolution (PSSR) - Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4-r1gE7Iamv",
        "colab_type": "text"
      },
      "source": [
        "# **1. Preparation: Set the Runtime type and mount your Google Drive**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5_nSag2fU94",
        "colab_type": "text"
      },
      "source": [
        "## **1.1. Set the Runtime type**\n",
        "---\n",
        "\n",
        "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "<font size = 4>**Accelator: GPU** *(Graphics processing unit (GPU)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDhmUgqCStlm",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "67fd20f6-933e-4058-8f8f-4c320105b8aa"
      },
      "source": [
        "#Run this cell to check if you have GPU access\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name()=='':\n",
        "  print('You do not have GPU access.') \n",
        "  print('Did you change your runtime ?') \n",
        "  print('If the runtime settings are correct then Google did not allocate GPU to your session')\n",
        "  print('Expect slow performance. To access GPU try reconnecting later')\n",
        "else:\n",
        "  print('You have GPU access')\n",
        "\n",
        "from tensorflow.python.client import device_lib \n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "You have GPU access\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 10765735311409383637, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 2317427044891050265\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 11729913141592060865\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 6927160916135005224\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqBTeLaImnU",
        "colab_type": "text"
      },
      "source": [
        "## **1.2. Mount your Google Drive**\n",
        "---\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive. \n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Djr8v-5pPk",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "56f8bf22-0d17-44ba-cd55-4667cb67ac3e"
      },
      "source": [
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TkQcROufgwL",
        "colab_type": "text"
      },
      "source": [
        "## **1.3. Install PSSR and dependencies**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5r0Gp7MwZLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9dbb791f-1484-4091-f5b4-907652c0d0b9"
      },
      "source": [
        "!pip install czifile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting czifile\n",
            "  Downloading https://files.pythonhosted.org/packages/37/86/3d0b1829c8c24eb1a4214f098a02442209f80302766203db33c99a4681ec/czifile-2019.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tifffile>=2019.7.2 in /usr/local/lib/python3.6/dist-packages (from czifile) (2020.6.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from czifile) (1.18.5)\n",
            "Installing collected packages: czifile\n",
            "Successfully installed czifile-2019.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS7lCdiQf_0T",
        "colab_type": "text"
      },
      "source": [
        "## **1.4. Specify your working folder - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmx810jDXTbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = \"gdrive/My Drive/PSSR-master\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMetHM56gMkf",
        "colab_type": "text"
      },
      "source": [
        "# **2. PSSR - Generate training datasets**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vETWgkZ5v4dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, root_path)\n",
        "from fastai.script import *\n",
        "from fastai.vision import *\n",
        "from utils import *\n",
        "from utils.crappifiers import *\n",
        "from pathlib import Path\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from time import sleep\n",
        "import torchvision\n",
        "import shutil\n",
        "import PIL\n",
        "import czifile\n",
        "import glob\n",
        "from PIL import Image\n",
        "from skimage.transform import rescale\n",
        "from skimage import filters\n",
        "from skimage.util import random_noise\n",
        "from scipy.ndimage.interpolation import zoom as npzoom\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 99999999999999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtFeMaEDIMI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def need_cache_flush(tile_stats, last_stats):\n",
        "    if last_stats is None: return True\n",
        "    if tile_stats['fn'] != last_stats['fn']: return True\n",
        "    return False\n",
        "\n",
        "def get_tile_puller(tile_stat, crap_func, t_frames, z_frames):\n",
        "    fn = tile_stat['fn']\n",
        "    ftype = tile_stat['ftype']\n",
        "    nz = tile_stat['nz']\n",
        "    nt = tile_stat['nt']\n",
        "\n",
        "    half_z = z_frames // 2\n",
        "    half_t = t_frames // 2\n",
        "\n",
        "    if ftype == 'czi':\n",
        "        img_f = czifile.CziFile(fn)\n",
        "        proc_axes, proc_shape = get_czi_shape_info(img_f)\n",
        "        img_data = img_f.asarray()\n",
        "        img_data = img_data.astype(np.float32)\n",
        "\n",
        "        def czi_get(istat):\n",
        "            c,z,t,x,y,mi,ma,is_uint8,rmax,all_rmax,all_ma = [istat[fld] for fld in ['c','z','t','x','y','mi','ma','uint8','rmax','all_rmax','all_ma']]\n",
        "            if is_uint8:\n",
        "                mi, ma, rmax = 0., 255.0, 255.0\n",
        "                all_ma, all_rmax = 255.0, 255.0\n",
        "\n",
        "            t_slice = slice(t-half_t, t+half_t+1) if half_t > 0 else t\n",
        "            z_slice = slice(z-half_z, z+half_z+1) if half_z > 0 else z\n",
        "            idx = build_index(\n",
        "                proc_axes, {\n",
        "                    'C': c,\n",
        "                    'T': t_slice,\n",
        "                    'Z': z_slice,\n",
        "                    'X': slice(0, x),\n",
        "                    'Y': slice(0, y)\n",
        "                })\n",
        "            img = img_data[idx].copy()\n",
        "            img /= all_rmax\n",
        "            if len(img.shape) <= 2: img = img[None]\n",
        "            return img\n",
        "\n",
        "        img_get = czi_get\n",
        "        img_get._to_close = img_f\n",
        "    else:\n",
        "        pil_img = PIL.Image.open(fn)\n",
        "        def pil_get(istat):\n",
        "            c,z,t,x,y,mi,ma,is_uint8,rmax,all_rmax,all_ma = [istat[fld] for fld in ['c','z','t','x','y','mi','ma','uint8','rmax','all_rmax','all_ma']]\n",
        "            if half_t > 0: n_start, n_end = t-half_t, t+half_t+1\n",
        "            elif half_z > 0: n_start, n_end = z-half_z, z+half_z+1\n",
        "            else: n_start, n_end = 0,1\n",
        "\n",
        "            if is_uint8:\n",
        "                mi, ma, rmax = 0., 255.0, 255.0\n",
        "                all_ma, all_rmax = 255.0, 255.0\n",
        "\n",
        "            img_array = []\n",
        "            for ix in range(n_start, n_end):\n",
        "                pil_img.seek(ix)\n",
        "                pil_img.load()\n",
        "                img = np.array(pil_img)\n",
        "                if len(img.shape) > 2: img = img[:,:,0]\n",
        "                img_array.append(img.copy())\n",
        "\n",
        "            img = np.stack(img_array)\n",
        "            img = img.astype(np.float32)\n",
        "            img /= all_rmax\n",
        "            return img\n",
        "\n",
        "        img_get = pil_get\n",
        "        img_get._to_close = pil_img\n",
        "\n",
        "\n",
        "    def puller(istat, tile_folder, crap_folder, close_me=False):\n",
        "        if close_me:\n",
        "            img_get._to_close.close()\n",
        "            return None\n",
        "\n",
        "        id = istat['index']\n",
        "        fn = Path(istat['fn'])\n",
        "        tile_sz = istat['tile_sz']\n",
        "        c,z,t,x,y,mi,ma,is_uint8,rmax = [istat[fld] for fld in ['c','z','t','x','y','mi','ma','uint8','rmax']]\n",
        "\n",
        "        raw_data = img_get(istat)\n",
        "        img_data = (np.iinfo(np.uint8).max * raw_data).astype(np.uint8)\n",
        "\n",
        "        thresh = np.percentile(img_data, 2)\n",
        "        thresh_pct = (img_data > thresh).mean() * 0.30\n",
        "\n",
        "        frame_count = img_data.shape[0]\n",
        "        mid_frame = frame_count // 2\n",
        "        crop_img, box = draw_random_tile(img_data[mid_frame], istat['tile_sz'], thresh, thresh_pct)\n",
        "        crop_img.save(tile_folder/f'{id:06d}_{fn.stem}.tif')\n",
        "        if crap_func and crap_folder:\n",
        "            if frame_count > 1:\n",
        "                crap_data = []\n",
        "                for i in range(frame_count):\n",
        "                    frame_img = img_data[i, box[0]:box[2], box[1]:box[3]]\n",
        "                    crap_frame = crap_func(frame_img)\n",
        "                    crap_data.append(np.array(crap_frame))\n",
        "                multi_array = np.stack(crap_data)\n",
        "                np.save(crap_folder/f'{id:06d}_{fn.stem}.npy', multi_array)\n",
        "            else:\n",
        "                crap_img = crap_func(crop_img)\n",
        "                crap_img.save(crap_folder/f'{id:06d}_{fn.stem}.tif')\n",
        "\n",
        "        info = dict(istat)\n",
        "        info['id'] = id\n",
        "        info['box'] = box\n",
        "        info['tile_sz'] = tile_sz\n",
        "        crop_data = np.array(crop_img)\n",
        "        info['after_mean'] = crop_data.mean()\n",
        "        info['after_sd'] = crop_data.std()\n",
        "        info['after_max'] = crop_data.max()\n",
        "        info['after_min'] = crop_data.min()\n",
        "        return info\n",
        "\n",
        "    return puller\n",
        "\n",
        "def check_info(info, t_frames, z_frames):\n",
        "    t_space = t_frames // 2\n",
        "    z_space = z_frames // 2\n",
        "\n",
        "    z_ok = (info['nz'] >= z_frames) and (info['z'] >= z_space) and (info['z'] < (info['nz']-z_space))\n",
        "    t_ok = (info['nt'] >= t_frames) and (info['t'] >= t_space) and (info['t'] < (info['nt']-t_space))\n",
        "\n",
        "    return t_ok and z_ok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCG3IlyEjzBa",
        "colab_type": "text"
      },
      "source": [
        "## **2.1. Specify your datasource - need your input**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZ7jTg7E5XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = 'datasets' #dataset folder, Path\n",
        "info = 'live_mitotrakcer.csv' #path of the metadata csv file, Path\n",
        "tile = 512 #generated training tile size, int\n",
        "n_train: 500 #number of train tiles, int\n",
        "n_valid: 50 #number of validation tiles', int\n",
        "crap_func = 'new_crap_AG_SP' #crappifier name, str, check utils/crappifiers.py for more details\n",
        "n_frames = 1 #number of frames, int, 1 if singleframe, >1 if multiframe, 5 for multiframe by default\n",
        "lr_type = 's' # (s)ingle, (t) multi or (z) multi', string, if multiframe, t if XYT time-lapse, z if XYZ 3D stack\n",
        "scale = 4 # upsample factor, int\n",
        "upsample = False # if LR-Bilinear is needed to save to disk, boolean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmTld6FTyqbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "up = 'up' if upsample else ''\n",
        "if lr_type not in ['s','t','z']:\n",
        "    print('lr_type should be s, t or z')\n",
        "    return 1\n",
        "\n",
        "if lr_type == 's':\n",
        "    z_frames, t_frames = 1, 1\n",
        "elif lr_type == 't':\n",
        "    z_frames, t_frames = 1, n_frames\n",
        "elif lr_type == 'z':\n",
        "    z_frames, t_frames = n_frames, 1\n",
        "\n",
        "out = ensure_folder(out/f'{lr_type}_{n_frames}_{info.stem}_{crap_func}')\n",
        "if out.exists(): shutil.rmtree(out)\n",
        "out.mkdir(parents=True, mode=0o775, exist_ok=True)\n",
        "\n",
        "crap_func = eval(crap_func)\n",
        "if not crap_func is None:\n",
        "    if not callable(crap_func):\n",
        "        print('crap_func is not callable')\n",
        "        crap_func = None\n",
        "    else:\n",
        "        crap_func = partial(crap_func, scale=scale, upsample=upsample)\n",
        "\n",
        "info = pd.read_csv(info)\n",
        "info = info.loc[info.nz >= z_frames]\n",
        "info = info.loc[info.nt >= t_frames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szuxHh1XFnQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tile_infos = []\n",
        "for mode, n_samples in [('train', n_train),('valid', n_valid)]:\n",
        "    mode_info = info.loc[info.dsplit == mode]\n",
        "    categories = list(mode_info.groupby('category'))\n",
        "    files_by_category  = {c:list(info.groupby('fn')) for c,info in categories}\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        category, cat_df = random.choice(categories)\n",
        "        fn, item_df = random.choice(files_by_category[category])\n",
        "        legal_choices = [item_info for ix, item_info in item_df.iterrows() if check_info(item_info, t_frames, z_frames)]\n",
        "\n",
        "        assert(legal_choices)\n",
        "        item_info = random.choice(legal_choices)\n",
        "        for tile_sz in tile:\n",
        "            item_d = dict(item_info)\n",
        "            item_d['tile_sz'] = tile_sz\n",
        "            tile_infos.append(item_d)\n",
        "\n",
        "tile_info_df = pd.DataFrame(tile_infos).reset_index()\n",
        "print('num tile pulls:', len(tile_infos))\n",
        "print(tile_info_df.groupby('category').fn.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7w1fzWrO5-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_stat = None\n",
        "tile_pull_info = []\n",
        "tile_puller = None\n",
        "\n",
        "multi_str = f'_{lr_type}_{n_frames}' if lr_type != 's' else ''\n",
        "mbar = master_bar(tile_info_df.groupby('fn'))\n",
        "for fn, tile_stats in mbar:\n",
        "    for i, tile_stat in progress_bar(list(tile_stats.iterrows()), parent=mbar):\n",
        "        try:\n",
        "            mode = tile_stat['dsplit']\n",
        "            category = tile_stat['category']\n",
        "            tile_sz = tile_stat['tile_sz']\n",
        "            tile_folder = ensure_folder(out / f'hr_t_{tile_sz}{multi_str}' / mode / category)\n",
        "            if crap_func:\n",
        "                crap_folder = ensure_folder(out / f'lr{up}_t_{tile_sz}{multi_str}' / mode / category)\n",
        "            else: crap_folder = None\n",
        "\n",
        "            if need_cache_flush(tile_stat, last_stat):\n",
        "                if tile_puller:\n",
        "                    tile_puller(None, None, None, close_me=True)\n",
        "                last_stat = tile_stat.copy()\n",
        "                tile_sz = tile_stat['tile_sz']\n",
        "                tile_puller = get_tile_puller(tile_stat, crap_func, t_frames, z_frames)\n",
        "            tile_pull_info.append(tile_puller(tile_stat, tile_folder, crap_folder))\n",
        "        except MemoryError as error:\n",
        "            # some files are too big to read\n",
        "            fn = Path(tile_stat['fn'])\n",
        "            print(f'too big: {fn.stem}')\n",
        "\n",
        "pd.DataFrame(tile_pull_info).to_csv(out/f'tiles{multi_str}.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}